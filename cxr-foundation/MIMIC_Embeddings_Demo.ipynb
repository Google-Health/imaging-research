{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Google-Health/imaging-research/blob/master/cxr-foundation/MIMIC_Embeddings_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/Google-Health/imaging-research/blob/master/cxr-foundation/MIMIC_Embeddings_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC CXR Embeddings Demo\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to train a simple neural network for a supervised classification task, using a set of Chest X-ray image embeddings.\n",
    "\n",
    "The datasets leveraged in this notebook are both derived from the [MIMIC-CXR Dataset](https://physionet.org/content/mimic-cxr/2.0.0/), which contains over 300,000 DICOMs and radiology reports:\n",
    "1. [The MIMIC-CXR JPG Dataset](https://physionet.org/content/mimic-cxr-jpg/2.0.0/) - contains JPG files derived from the DICOM images and structured labels derived from the free-text reports.\n",
    "2. [The MIMIC-CXR Image Embeddings Dataset](https://physionet.org/content/image-embeddings-mimic-cxr/1.0/) - which was generated from MIMIC-CXR using the Google Health [CXR Foundation tool](https://github.com/Google-Health/imaging-research/blob/master/cxr-foundation/README.md).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Data access** - the MIMIC datasets are access-controlled. Follow the instructions on the [files](https://physionet.org/content/image-embeddings-mimic-cxr/1.0/#files) section to get access to the data. Overall, you must:\n",
    "   - Be a credentialled PhysioNet user\n",
    "   - Complete the appropriate institutional research training and get it verified by PhysioNet\n",
    "   - Ensure the email you use to access Google Cloud is [selected](https://physionet.org/settings/cloud/) in your PhysioNet profile.\n",
    "   - Sign the data use agreement for each dataset\n",
    "   - Request access to the dataset's GCS bucket\n",
    "2. **Billing** - this notebook downloads data directly from PhysioNet's GCS buckets, which are set to [requester pays](https://cloud.google.com/storage/docs/requester-pays). Therefore you must have a Google Cloud project with an associated billing account. (The download cost in this notebook should be < $1)\n",
    "\n",
    "Note: PhysioNet hosts its data on its on-prem servers, which can be downloaded free of charge. Some of its databases are copied onto GCS buckets, which have much faster download speeds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if running notebook from Colab\n",
    "!git clone https://github.com/Google-Health/imaging-research.git\n",
    "!mv imaging-research/cxr-foundation/cxr_foundation ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-storage==2.8.0 \\\n",
    "    pandas==1.5.3 \\\n",
    "    tensorflow==2.12.0 \\\n",
    "    tf-models-official==2.12.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: If you are using Google Colab, you must restart the runtime after installing new packages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate to Access Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "# Authenticate user for access. There will be a popup asking you to sign in with your user and approve access.\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Process Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "\n",
    "from cxr_foundation.gcs import download_blob\n",
    "from cxr_foundation.mimic import parse_embedding_file_pattern\n",
    "\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "EMBEDDINGS_DATA_DIR = os.path.abspath(os.path.join(DATA_DIR, \"mimic-embeddings-files\"))\n",
    "\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Make a directory to download the data\n",
    "if not os.path.exists(DATA_DIR):\n",
    "  os.mkdir(DATA_DIR)\n",
    "\n",
    "if not os.path.exists(EMBEDDINGS_DATA_DIR):\n",
    "  os.mkdir(EMBEDDINGS_DATA_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Metadata\n",
    "\n",
    "Data source:\n",
    "- https://physionet.org/content/image-embeddings-mimic-cxr/1.0/\n",
    "- https://console.cloud.google.com/storage/browser/image-embeddings-mimic-cxr-1.0.physionet.org\n",
    "\n",
    "Download the checksums file which contains a list of the embeddings files. Extract the data components from the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_bucket = storage_client.bucket(\n",
    "    'image-embeddings-mimic-cxr-1.0.physionet.org')    \n",
    "\n",
    "# Download the checksums file which contains a records list\n",
    "download_blob(embeddings_bucket, \"SHA256SUMS.txt\", \"data/SHA256SUMS.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.read_csv(\"data/SHA256SUMS.txt\", delimiter=\" \", header=None, skiprows=[0])  # Skip the license file entry\n",
    "display(df_embeddings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_COL_NAME = \"embeddings_file\"  # Remote bucket embedding file location\n",
    "DL_COL_NAME = \"local_embeddings_file\"  # Download file to this location\n",
    "\n",
    "# Create additional columns from file path components\n",
    "df_embeddings = df_embeddings[[1]]\n",
    "df_embeddings.rename(columns={1: \"embeddings_file\"}, inplace=True)\n",
    "df_embeddings[[\"subject_id\",\"study_id\", \"dicom_id\"]] = df_embeddings.apply(\n",
    "    lambda x: parse_embedding_file_pattern(x[SOURCE_COL_NAME]), axis=1, result_type=\"expand\")\n",
    "df_embeddings[DL_COL_NAME] = df_embeddings[SOURCE_COL_NAME].apply(lambda x: os.path.join(EMBEDDINGS_DATA_DIR, os.path.basename(x)))  # For download\n",
    "\n",
    "display(df_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CXR Metadata\n",
    "\n",
    "Data source:\n",
    "- https://physionet.org/content/mimic-cxr-jpg/2.0.0/\n",
    "- https://console.cloud.google.com/storage/browser/mimic-cxr-jpg-2.0.0.physionet.org\n",
    "\n",
    "Download and visualize three metadata files:\n",
    "1. `mimic-cxr-2.0.0-metadata.csv`: Meta-data derived from the original DICOM files\n",
    "2. `mimic-cxr-2.0.0-split.csv`: A reference dataset split for studies using MIMIC-CXR-JPG\n",
    "3. `mimic-cxr-2.0.0-chexpert.csv`:  Lists all studies with labels generated by the CheXpert labeler.\n",
    "\n",
    "The first two files were used to generate the embeddings database. Embeddings files were only generated for the frontal view CXRs, so there are fewer embeddings files than there are original DICOMs/JPGs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr_jpg_bucket = storage_client.bucket(\n",
    "    'mimic-cxr-jpg-2.0.0.physionet.org')\n",
    "\n",
    "CXR_JPG_METADATA_FILES = (\n",
    "    \"mimic-cxr-2.0.0-metadata.csv.gz\",\n",
    "    \"mimic-cxr-2.0.0-split.csv.gz\",\n",
    "    \"mimic-cxr-2.0.0-chexpert.csv.gz\")\n",
    "\n",
    "for fname in CXR_JPG_METADATA_FILES:\n",
    "  download_blob(cxr_jpg_bucket, fname, f\"{DATA_DIR}/{fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CXR_JPG_METADATA_FILES = (\n",
    "    \"mimic-cxr-2.0.0-metadata.csv.gz\",\n",
    "    \"mimic-cxr-2.0.0-split.csv.gz\",\n",
    "    \"mimic-cxr-2.0.0-chexpert.csv.gz\")\n",
    "\n",
    "df_metadata = pd.read_csv(f\"data/{CXR_JPG_METADATA_FILES[0]}\", compression=\"gzip\")\n",
    "df_split = pd.read_csv(f\"data/{CXR_JPG_METADATA_FILES[1]}\", compression=\"gzip\")\n",
    "df_labels_chexpert = pd.read_csv(f\"data/{CXR_JPG_METADATA_FILES[2]}\", compression=\"gzip\")\n",
    "\n",
    "display(df_metadata.head())\n",
    "display(df_split.head())\n",
    "display(df_labels_chexpert.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the full labels file\n",
    "\n",
    "Join embeddings list with Chexpert metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each study contains one or more DICOMs\n",
    "# Chexpert labels df does not contain DICOM ID. Must join on (subject_id + study_id)\n",
    "df_labels_all = df_split.merge(df_labels_chexpert, on=['subject_id', 'study_id'])\n",
    "df_labels_all = df_labels_all.merge(df_metadata, on=['dicom_id'])\n",
    "df_labels_all = df_embeddings.merge(df_labels_all, on=['dicom_id'], how='left')\n",
    "\n",
    "display(df_labels_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Labels files for Individual Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of data frames for individual diagnoses\n",
    "diagnoses_dataframes = {}\n",
    "\n",
    "# Choose some of the Chexpert generated diagnoses\n",
    "for diagnosis in ('Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Fracture'):\n",
    "  # Remove missing/unsure labels\n",
    "  df_diagnosis = df_labels_all[df_labels_all[diagnosis].isin((0, 1))]\n",
    "  # Only extract required columns for the ML model\n",
    "  df_diagnosis = df_diagnosis[[diagnosis, SOURCE_COL_NAME, DL_COL_NAME, 'split']]\n",
    "  \n",
    "  diagnoses_dataframes[diagnosis] = df_diagnosis\n",
    "  df_diagnosis.to_csv(f'data/{diagnosis}.csv', index=False)\n",
    "  print(f\"Created {diagnosis}.csv with {len(df_diagnosis)} rows\")\n",
    "  display(df_diagnosis.nunique())\n",
    "  \n",
    "  # Show label and split value distributions\n",
    "  display(df_diagnosis[diagnosis].value_counts())\n",
    "  display(df_diagnosis['split'].value_counts())\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Embeddings Files for Model Training\n",
    "\n",
    "There are many labels for Cardiomegaly. We will train our model using the embeddings with this label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGNOSIS = 'Cardiomegaly'\n",
    "LABELS_CSV = f\"data/{DIAGNOSIS}.csv\"\n",
    "MAX_TRAINING_SAMPLES = 500\n",
    "MAX_VALIDATION_SAMPLES = 200\n",
    "\n",
    "df_diagnosis = pd.read_csv(LABELS_CSV)\n",
    "\n",
    "df_train = df_diagnosis[df_diagnosis[\"split\"] == \"train\"][:MAX_TRAINING_SAMPLES]\n",
    "df_validate = df_diagnosis[df_diagnosis[\"split\"] == \"validate\"][:MAX_VALIDATION_SAMPLES]\n",
    "     \n",
    "\n",
    "display(df_train)\n",
    "display(df_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~2m\n",
    "for i, row in df_train.iterrows():\n",
    "    download_blob(embeddings_bucket, row[SOURCE_COL_NAME], row[DL_COL_NAME], print_name=\"dest\")\n",
    "\n",
    "for i, row in df_validate.iterrows():\n",
    "    download_blob(embeddings_bucket, row[SOURCE_COL_NAME], row[DL_COL_NAME], print_name=\"dest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect some embeddings files. A single file is only 5.6kb\n",
    "from cxr_foundation import embeddings_data\n",
    "\n",
    "filename = df_train[DL_COL_NAME][0]\n",
    "\n",
    "# Read the tf.train.Example object from the first tfrecord file\n",
    "example = embeddings_data.read_record_example(filename)\n",
    "print(example)\n",
    "\n",
    "# If you don't care about the structure of the .tfrecord file, and/or if\n",
    "# you don't use Tensorflow, just use the following function to read\n",
    "# the values directly into a numpy array.\n",
    "values = embeddings_data.read_record_values(filename)\n",
    "print(values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "\n",
    "def create_model(heads,\n",
    "                 embeddings_size=1376,\n",
    "                 learning_rate=0.1,\n",
    "                 end_lr_factor=1.0,\n",
    "                 dropout=0.0,\n",
    "                 decay_steps=1000,\n",
    "                 loss_weights=None,\n",
    "                 hidden_layer_sizes=[512, 256],\n",
    "                 weight_decay=0.0,\n",
    "                 seed=None):\n",
    "  \"\"\"\n",
    "  Creates linear probe or multilayer perceptron using LARS + cosine decay.\n",
    "\n",
    "  \"\"\"\n",
    "  inputs = tf.keras.Input(shape=(embeddings_size,))\n",
    "  hidden = inputs\n",
    "  # If no hidden_layer_sizes are provided, model will be a linear probe.\n",
    "  for size in hidden_layer_sizes:\n",
    "    hidden = tf.keras.layers.Dense(\n",
    "        size,\n",
    "        activation='relu',\n",
    "        kernel_initializer=tf.keras.initializers.HeUniform(seed=seed),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2=weight_decay),\n",
    "        bias_regularizer=tf.keras.regularizers.l2(l2=weight_decay))(\n",
    "            hidden)\n",
    "    hidden = tf.keras.layers.BatchNormalization()(hidden)\n",
    "    hidden = tf.keras.layers.Dropout(dropout, seed=seed)(hidden)\n",
    "  output = tf.keras.layers.Dense(\n",
    "      units=len(heads),\n",
    "      activation='sigmoid',\n",
    "      kernel_initializer=tf.keras.initializers.HeUniform(seed=seed))(\n",
    "          hidden)\n",
    "\n",
    "  outputs = {}\n",
    "  for i, head in enumerate(heads):\n",
    "    outputs[head] = tf.keras.layers.Lambda(\n",
    "        lambda x: x[..., i:i + 1], name=head.lower())(\n",
    "            output)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "  learning_rate_fn = tf.keras.experimental.CosineDecay(\n",
    "      tf.cast(learning_rate, tf.float32),\n",
    "      tf.cast(decay_steps, tf.float32),\n",
    "      alpha=tf.cast(end_lr_factor, tf.float32))\n",
    "      \n",
    "  model.compile(\n",
    "      optimizer=tfm.optimization.lars_optimizer.LARS(\n",
    "          learning_rate=learning_rate_fn),\n",
    "      loss=dict([(head, 'binary_crossentropy') for head in heads]),\n",
    "      loss_weights=loss_weights or dict([(head, 1.) for head in heads]),\n",
    "      weighted_metrics=['AUC'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation Datasets\n",
    "training_data = embeddings_data.get_dataset(filenames=df_train[DL_COL_NAME].values,\n",
    "                        labels=df_train[DIAGNOSIS].values)\n",
    "\n",
    "\n",
    "validation_data = embeddings_data.get_dataset(filenames=df_validate[DL_COL_NAME].values,\n",
    "                        labels=df_validate[DIAGNOSIS].values)\n",
    "\n",
    "# Create and train the model\n",
    "model = create_model([DIAGNOSIS])\n",
    "\n",
    "model.fit(\n",
    "    x=training_data.batch(512).prefetch(tf.data.AUTOTUNE).cache(),\n",
    "    validation_data=validation_data,\n",
    "    epochs=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: serialize model for later use\n",
    "# model.save(\"embeddings_model\", include_optimizer=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cxr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3ac608b8f9188be2227ae82298dfd5de684cbdc4496f362d4b3b9040509447c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
