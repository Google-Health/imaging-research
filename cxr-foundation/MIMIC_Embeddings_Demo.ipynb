{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Google-Health/imaging-research/blob/mimic-demo/cxr-foundation/MIMIC_Embeddings_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Google-Health/imaging-research/blob/mimic-demo/cxr-foundation/MIMIC_Embeddings_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC CXR Embeddings Demo\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to train a simple neural network for a supervised classification task, using a set of Chest X-ray image embeddings.\n",
    "\n",
    "The datasets leveraged in this notebook are both derived from the [MIMIC-CXR Dataset](https://physionet.org/content/mimic-cxr/2.0.0/), which contains over 300,000 DICOMs and radiology reports:\n",
    "1. [The MIMIC-CXR JPG Dataset](https://physionet.org/content/mimic-cxr-jpg/2.0.0/) - contains JPG files derived from the DICOM images and structured labels derived from the free-text reports.\n",
    "2. [The MIMIC-CXR Image Embeddings Dataset](https://physionet.org/content/image-embeddings-mimic-cxr/1.0/) - which was generated from MIMIC-CXR using the Google Health [CXR Foundation tool](https://github.com/Google-Health/imaging-research/blob/master/cxr-foundation/README.md).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Data access** - the MIMIC datasets are access-controlled. Follow the instructions on the [files](https://physionet.org/content/image-embeddings-mimic-cxr/1.0/#files) section to get access to the data. Overall, you must:\n",
    "   - Be a credentialled PhysioNet user\n",
    "   - Complete the appropriate institutional research training and get it verified by PhysioNet\n",
    "   - Ensure the email you use to access Google Cloud is [selected](https://physionet.org/settings/cloud/) in your PhysioNet profile.\n",
    "   - Sign the data use agreement for each dataset\n",
    "   - Request access to the dataset's GCS bucket\n",
    "2. **Billing** - this notebook downloads data directly from PhysioNet's GCS buckets, which are set to [requester pays](https://cloud.google.com/storage/docs/requester-pays). Therefore you must have a Google Cloud project with an associated billing account. (The download cost in this notebook should be < $1)\n",
    "\n",
    "Note: PhysioNet hosts its data on its on-prem servers, which can be downloaded free of charge. Some of its databases are copied onto GCS buckets, which have much faster download speeds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if running notebook from Colab\n",
    "!git clone -b mimic-demo https://github.com/Google-Health/imaging-research.git\n",
    "!mv imaging-research/cxr-foundation/cxr_foundation ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-storage==1.42.3 \\\n",
    "    pandas==1.3.5 \\\n",
    "    tensorflow==2.10.0 \\\n",
    "    tf-models-official==2.10.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: If you are using Google Colab, you must restart the runtime after installing new packages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate to Access Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "# Authenticate user for access. There will be a popup asking you to sign in with your user and approve access.\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Required: set a project ID for the requester pays GCS downloads\n",
    "PROJECT_ID = '[your Cloud Platform project ID]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Process Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "\n",
    "def download_blob(bucket, source_blob_name: str, destination_file_name: str):\n",
    "    \"\"\"\n",
    "    Downloads a blob from the bucket.\n",
    "    \n",
    "    https://cloud.google.com/storage/docs/downloading-objects\n",
    "    \"\"\"\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "    print(f\"Downloaded {source_blob_name}\")\n",
    "\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Make a directory to download the data\n",
    "if not os.path.exists('data'):\n",
    "  os.mkdir('data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Metadata\n",
    "\n",
    "Data source:\n",
    "- https://physionet.org/content/image-embeddings-mimic-cxr/1.0/\n",
    "- https://console.cloud.google.com/storage/browser/image-embeddings-mimic-cxr-1.0.physionet.org\n",
    "\n",
    "Download the checksums file which contains a list of the embeddings files. Extract the data components from the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_bucket = storage_client.bucket(\n",
    "    'image-embeddings-mimic-cxr-1.0.physionet.org', user_project=PROJECT_ID)    \n",
    "\n",
    "# Download the checksums file which contains a records list\n",
    "download_blob(embeddings_bucket, \"SHA256SUMS.txt\", \"data/SHA256SUMS.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.read_csv(\"data/SHA256SUMS.txt\", delimiter=\" \", header=None, skiprows=[0])  # Skip the license file entry\n",
    "display(df_embeddings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Example: 'files/p19/p19692222/s59566639/965b6053-a2c70d67-c0467ca6-02372346-fb7c6224.tfrecord'\n",
    "FILE_PATTERN = re.compile(r\"files/(?:\\w+)/p(?P<subject_id>\\w+)/s(?P<study_id>\\w+)/(?P<dicom_id>[\\w-]+)\\.tfrecord\")\n",
    "\n",
    "def parse_file_pattern(file_path: str):\n",
    "    \"\"\"\n",
    "    Extracts the subject_id, study_id, and dicom_id\n",
    "    from the full file path string.\n",
    "    \"\"\"\n",
    "    match = FILE_PATTERN.fullmatch(file_path)\n",
    "    if not match:\n",
    "        raise Exception(f\"Failed to match file path: {file_path}\")\n",
    "    return (int(match[1]), int(match[2]), match[3])\n",
    "\n",
    "# Create additional columns from file path components\n",
    "df_embeddings = df_embeddings[[1]]\n",
    "df_embeddings.rename(columns={1: \"embedding_file\"}, inplace=True)\n",
    "df_embeddings[[\"subject_id\",\"study_id\", \"dicom_id\"]] = df_embeddings.apply(\n",
    "    lambda x: parse_file_pattern(x[\"embedding_file\"]), axis=1, result_type=\"expand\")\n",
    "\n",
    "display(df_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CXR Metadata\n",
    "\n",
    "Data source:\n",
    "- https://physionet.org/content/mimic-cxr-jpg/2.0.0/\n",
    "- https://console.cloud.google.com/storage/browser/mimic-cxr-jpg-2.0.0.physionet.org\n",
    "\n",
    "Download and visualize three metadata files:\n",
    "1. `mimic-cxr-2.0.0-metadata.csv`: Meta-data derived from the original DICOM files\n",
    "2. `mimic-cxr-2.0.0-split.csv`: A reference dataset split for studies using MIMIC-CXR-JPG\n",
    "3. `mimic-cxr-2.0.0-chexpert.csv`:  Lists all studies with labels generated by the CheXpert labeler.\n",
    "\n",
    "The first two files were used to generate the embeddings database. Embeddings files were only generated for the frontal view CXRs, so there are fewer embeddings files than there are original DICOMs/JPGs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr_jpg_bucket = storage_client.bucket(\n",
    "    'mimic-cxr-jpg-2.0.0.physionet.org', user_project=PROJECT_ID)\n",
    "\n",
    "CXR_JPG_METADATA_FILES = (\n",
    "    \"mimic-cxr-2.0.0-metadata.csv.gz\",\n",
    "    \"mimic-cxr-2.0.0-split.csv.gz\",\n",
    "    \"mimic-cxr-2.0.0-chexpert.csv.gz\")\n",
    "\n",
    "for fname in CXR_JPG_METADATA_FILES:\n",
    "  download_blob(cxr_jpg_bucket, fname, f\"data/{fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(f\"data/{CXR_JPG_METADATA_FILES[0]}\", compression=\"gzip\")\n",
    "df_split = pd.read_csv(f\"data/{CXR_JPG_METADATA_FILES[1]}\", compression=\"gzip\")\n",
    "df_labels_chexpert = pd.read_csv(f\"data/{CXR_JPG_METADATA_FILES[2]}\", compression=\"gzip\")\n",
    "\n",
    "display(df_metadata.head())\n",
    "display(df_split.head())\n",
    "display(df_labels_chexpert.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the full labels file\n",
    "\n",
    "Join embeddings list with Chexpert metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each study contains one or more DICOMs\n",
    "# Chexpert labels df does not contain DICOM ID. Must join on (subject_id + study_id)\n",
    "df_labels = df_split.merge(df_labels_chexpert, on=['subject_id', 'study_id'])\n",
    "df_labels = df_labels.merge(df_metadata, on=['dicom_id'])\n",
    "df_labels = df_embeddings.merge(df_labels, on=['dicom_id'], how='left')\n",
    "\n",
    "display(df_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Labels files for Individual Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some of the Chexpert generated diagnoses\n",
    "for diagnosis in ('Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Fracture'):\n",
    "  # Remove missing/unsure labels\n",
    "  df = df_labels[df_labels[diagnosis].isin((0, 1))]\n",
    "  # Only need diagnosis, image_id, and train/test/val split for ML model\n",
    "  df = df[[diagnosis, 'dicom_id', 'embedding_file', 'split']]\n",
    "  # Workaround for: https://github.com/Google-Health/imaging-research/issues/7\n",
    "  # You don't need to do this if not using train_lib.py\n",
    "  df['image_id'] = df['embedding_file'].apply(lambda x: f\"gs://superrad/inputs/mimic-cxr/{x.replace('tfrecord', 'dcm')}\")\n",
    "  df.to_csv(f'data/{diagnosis}.csv', index=False)\n",
    "  print(f\"Created {diagnosis}.csv with {len(df)} rows\")\n",
    "  display(df.nunique())\n",
    "  # Show label and split value distributions\n",
    "  display(df[diagnosis].value_counts())\n",
    "  display(df['split'].value_counts())\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Embeddings Files for Model Training\n",
    "\n",
    "There are many labels for Cardiomegaly. We will train our model using the embeddings with this label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGNOSIS = 'Cardiomegaly'\n",
    "LABELS_CSV = f\"data/{DIAGNOSIS}.csv\"\n",
    "MAX_TRAINING_SAMPLES = 500\n",
    "MAX_VALIDATION_SAMPLES = 200\n",
    "\n",
    "# Download the embeddings files here\n",
    "EMBEDDINGS_DIR = 'data/mimic-embeddings-files'\n",
    "\n",
    "if not os.path.exists(EMBEDDINGS_DIR):\n",
    "  os.mkdir(EMBEDDINGS_DIR)\n",
    "\n",
    "df = pd.read_csv(LABELS_CSV)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training files\n",
    "for i, row in df[df[\"split\"] == \"train\"][:MAX_TRAINING_SAMPLES].iterrows():\n",
    "    download_blob(embeddings_bucket, row[\"embedding_file\"], f\"{EMBEDDINGS_DIR}/{row['dicom_id']}.tfrecord\")\n",
    "    \n",
    "# Download validation files\n",
    "for i, row in df[df[\"split\"] == \"validate\"][:MAX_VALIDATION_SAMPLES].iterrows():\n",
    "    download_blob(embeddings_bucket, row[\"embedding_file\"], f\"{EMBEDDINGS_DIR}/{row['dicom_id']}.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect an embeddings file. A single file is only 5.6kb\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(glob.glob(f\"{EMBEDDINGS_DIR}/*.tfrecord\"))\n",
    "for raw_record in raw_dataset.take(1):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(raw_record.numpy())\n",
    "  print(example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m cxr_foundation.train \\\n",
    "  --train_split_name train \\\n",
    "  --tune_split_name validate \\\n",
    "  --labels_csv {LABELS_CSV} \\\n",
    "  --head_name {DIAGNOSIS} \\\n",
    "  --data_dir {EMBEDDINGS_DIR} \\\n",
    "  --batch_size {BATCH_SIZE} \\\n",
    "  --num_epochs {NUM_EPOCHS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cxr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3ac608b8f9188be2227ae82298dfd5de684cbdc4496f362d4b3b9040509447c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
