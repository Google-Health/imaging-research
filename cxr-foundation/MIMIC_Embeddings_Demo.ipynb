{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Google-Health/imaging-research/blob/master/cxr-foundation/MIMIC_Embeddings_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/Google-Health/imaging-research/blob/master/cxr-foundation/MIMIC_Embeddings_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC CXR Embeddings Demo\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to train a simple neural network for a supervised classification task, using a set of Chest X-ray image embeddings.\n",
    "\n",
    "The datasets leveraged in this notebook are both derived from the [MIMIC-CXR Dataset](https://physionet.org/content/mimic-cxr/2.0.0/), which contains over 300,000 DICOMs and radiology reports:\n",
    "1. [The MIMIC-CXR JPG Dataset](https://physionet.org/content/mimic-cxr-jpg/2.0.0/) - contains JPG files derived from the DICOM images and structured labels derived from the free-text reports.\n",
    "2. [The MIMIC-CXR Image Embeddings Dataset](https://physionet.org/content/image-embeddings-mimic-cxr/1.0/) - which was generated from MIMIC-CXR using the Google Health [CXR Foundation tool](https://github.com/Google-Health/imaging-research/blob/master/cxr-foundation/README.md).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Data access** - the MIMIC datasets are access-controlled. Follow the instructions on the [files](https://physionet.org/content/image-embeddings-mimic-cxr/1.0/#files) section to get access to the data. Overall, you must:\n",
    "   - Be a credentialled PhysioNet user\n",
    "   - Complete the appropriate institutional research training and get it verified by PhysioNet\n",
    "   - Ensure the email you use to access Google Cloud is [selected](https://physionet.org/settings/cloud/) in your PhysioNet profile.\n",
    "   - Sign the data use agreement for each dataset\n",
    "   - Request access to the dataset's GCS bucket\n",
    "2. **Billing** - this notebook downloads data directly from PhysioNet's GCS buckets, which are set to [requester pays](https://cloud.google.com/storage/docs/requester-pays). Therefore you must have a Google Cloud project with an associated billing account. (The download cost in this notebook should be < $1)\n",
    "\n",
    "Note: PhysioNet hosts its data on its on-prem servers, which can be downloaded free of charge. Some of its databases are copied onto GCS buckets, which have much faster download speeds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if running notebook from Colab\n",
    "!git clone https://github.com/Google-Health/imaging-research.git\n",
    "!mv imaging-research/cxr-foundation/cxr_foundation ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-storage==1.42.3 \\\n",
    "    pandas==1.3.5 \\\n",
    "    tensorflow==2.10.0 \\\n",
    "    tf-models-official==2.10.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: If you are using Google Colab, you must restart the runtime after installing new packages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate to Access Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "# Authenticate user for access. There will be a popup asking you to sign in with your user and approve access.\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Required: set a project ID for the requester pays GCS downloads.\n",
    "PROJECT_ID = '[your Cloud Platform project ID]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Process Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "\n",
    "def download_blob(bucket, source_blob_name: str, destination_file_name: str):\n",
    "    \"\"\"\n",
    "    Downloads a blob from the bucket.\n",
    "    \n",
    "    https://cloud.google.com/storage/docs/downloading-objects\n",
    "    \"\"\"\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    try:\n",
    "      blob.download_to_filename(destination_file_name)\n",
    "    except Exception as e:\n",
    "      print('Error during download - do you have the right permissions?')\n",
    "      print(e)\n",
    "      return\n",
    "    print(f\"Downloaded {source_blob_name}\")\n",
    "\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Make a directory to download the data\n",
    "if not os.path.exists('data'):\n",
    "  os.mkdir('data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Metadata\n",
    "\n",
    "Data source:\n",
    "- https://physionet.org/content/image-embeddings-mimic-cxr/1.0/\n",
    "- https://console.cloud.google.com/storage/browser/image-embeddings-mimic-cxr-1.0.physionet.org\n",
    "\n",
    "Download the checksums file which contains a list of the embeddings files. Extract the data components from the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_bucket = storage_client.bucket(\n",
    "    'image-embeddings-mimic-cxr-1.0.physionet.org', user_project=PROJECT_ID)    \n",
    "\n",
    "# Download the checksums file which contains a records list\n",
    "download_blob(embeddings_bucket, \"SHA256SUMS.txt\", \"data/SHA256SUMS.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.read_csv(\"data/SHA256SUMS.txt\", delimiter=\" \", header=None, skiprows=[0])  # Skip the license file entry\n",
    "display(df_embeddings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Example: 'files/p19/p19692222/s59566639/965b6053-a2c70d67-c0467ca6-02372346-fb7c6224.tfrecord'\n",
    "FILE_PATTERN = re.compile(r\"files/(?:\\w+)/p(?P<subject_id>\\w+)/s(?P<study_id>\\w+)/(?P<dicom_id>[\\w-]+)\\.tfrecord\")\n",
    "\n",
    "def parse_file_pattern(file_path: str):\n",
    "    \"\"\"\n",
    "    Extracts the subject_id, study_id, and dicom_id\n",
    "    from the full file path string.\n",
    "    \"\"\"\n",
    "    match = FILE_PATTERN.fullmatch(file_path)\n",
    "    if not match:\n",
    "        raise Exception(f\"Failed to match file path: {file_path}\")\n",
    "    return (int(match[1]), int(match[2]), match[3])\n",
    "\n",
    "# Create additional columns from file path components\n",
    "df_embeddings = df_embeddings[[1]]\n",
    "df_embeddings.rename(columns={1: \"embedding_file\"}, inplace=True)\n",
    "df_embeddings[[\"subject_id\",\"study_id\", \"dicom_id\"]] = df_embeddings.apply(\n",
    "    lambda x: parse_file_pattern(x[\"embedding_file\"]), axis=1, result_type=\"expand\")\n",
    "\n",
    "display(df_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CXR Metadata\n",
    "\n",
    "Data source:\n",
    "- https://physionet.org/content/mimic-cxr-jpg/2.0.0/\n",
    "- https://console.cloud.google.com/storage/browser/mimic-cxr-jpg-2.0.0.physionet.org\n",
    "\n",
    "Download and visualize three metadata files:\n",
    "1. `mimic-cxr-2.0.0-metadata.csv`: Meta-data derived from the original DICOM files\n",
    "2. `mimic-cxr-2.0.0-split.csv`: A reference dataset split for studies using MIMIC-CXR-JPG\n",
    "3. `mimic-cxr-2.0.0-chexpert.csv`:  Lists all studies with labels generated by the CheXpert labeler.\n",
    "\n",
    "The first two files were used to generate the embeddings database. Embeddings files were only generated for the frontal view CXRs, so there are fewer embeddings files than there are original DICOMs/JPGs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr_jpg_bucket = storage_client.bucket(\n",
    "    'mimic-cxr-jpg-2.0.0.physionet.org', user_project=PROJECT_ID)\n",
    "\n",
    "CXR_JPG_METADATA_FILES = (\n",
    "    \"mimic-cxr-2.0.0-metadata.csv.gz\",\n",
    "    \"mimic-cxr-2.0.0-split.csv.gz\",\n",
    "    \"mimic-cxr-2.0.0-chexpert.csv.gz\")\n",
    "\n",
    "for fname in CXR_JPG_METADATA_FILES:\n",
    "  download_blob(cxr_jpg_bucket, fname, f\"data/{fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(f\"data/{CXR_JPG_METADATA_FILES[0]}\", compression=\"gzip\")\n",
    "df_split = pd.read_csv(f\"data/{CXR_JPG_METADATA_FILES[1]}\", compression=\"gzip\")\n",
    "df_labels_chexpert = pd.read_csv(f\"data/{CXR_JPG_METADATA_FILES[2]}\", compression=\"gzip\")\n",
    "\n",
    "display(df_metadata.head())\n",
    "display(df_split.head())\n",
    "display(df_labels_chexpert.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the full labels file\n",
    "\n",
    "Join embeddings list with Chexpert metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each study contains one or more DICOMs\n",
    "# Chexpert labels df does not contain DICOM ID. Must join on (subject_id + study_id)\n",
    "df_labels = df_split.merge(df_labels_chexpert, on=['subject_id', 'study_id'])\n",
    "df_labels = df_labels.merge(df_metadata, on=['dicom_id'])\n",
    "df_labels = df_embeddings.merge(df_labels, on=['dicom_id'], how='left')\n",
    "\n",
    "display(df_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Labels files for Individual Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some of the Chexpert generated diagnoses\n",
    "for diagnosis in ('Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Fracture'):\n",
    "  # Remove missing/unsure labels\n",
    "  df = df_labels[df_labels[diagnosis].isin((0, 1))]\n",
    "  # Only need diagnosis, image_id, and train/test/val split for ML model\n",
    "  df = df[[diagnosis, 'dicom_id', 'embedding_file', 'split']]\n",
    "  # Workaround for: https://github.com/Google-Health/imaging-research/issues/7\n",
    "  # You don't need to do this if not using train_lib.py\n",
    "  df['image_id'] = df['embedding_file'].apply(lambda x: f\"gs://superrad/inputs/mimic-cxr/{x.replace('tfrecord', 'dcm')}\")\n",
    "  df.to_csv(f'data/{diagnosis}.csv', index=False)\n",
    "  print(f\"Created {diagnosis}.csv with {len(df)} rows\")\n",
    "  display(df.nunique())\n",
    "  # Show label and split value distributions\n",
    "  display(df[diagnosis].value_counts())\n",
    "  display(df['split'].value_counts())\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Embeddings Files for Model Training\n",
    "\n",
    "There are many labels for Cardiomegaly. We will train our model using the embeddings with this label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGNOSIS = 'Cardiomegaly'\n",
    "LABELS_CSV = f\"data/{DIAGNOSIS}.csv\"\n",
    "MAX_TRAINING_SAMPLES = 500\n",
    "MAX_VALIDATION_SAMPLES = 200\n",
    "\n",
    "# Download the embeddings files here\n",
    "EMBEDDINGS_DIR = 'data/mimic-embeddings-files'\n",
    "\n",
    "if not os.path.exists(EMBEDDINGS_DIR):\n",
    "  os.mkdir(EMBEDDINGS_DIR)\n",
    "\n",
    "df = pd.read_csv(LABELS_CSV)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training files\n",
    "for i, row in df[df[\"split\"] == \"train\"][:MAX_TRAINING_SAMPLES].iterrows():\n",
    "    download_blob(embeddings_bucket, row[\"embedding_file\"], f\"{EMBEDDINGS_DIR}/{row['dicom_id']}.tfrecord\")\n",
    "    \n",
    "# Download validation files\n",
    "for i, row in df[df[\"split\"] == \"validate\"][:MAX_VALIDATION_SAMPLES].iterrows():\n",
    "    download_blob(embeddings_bucket, row[\"embedding_file\"], f\"{EMBEDDINGS_DIR}/{row['dicom_id']}.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect an embeddings file. A single file is only 5.6kb\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(glob.glob(f\"{EMBEDDINGS_DIR}/*.tfrecord\"))\n",
    "for raw_record in raw_dataset.take(1):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(raw_record.numpy())\n",
    "  print(example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from cxr_foundation import train_lib\n",
    "\n",
    "\n",
    "# Copy of cxr_foundation.train_lib.create_model\n",
    "# Use original function for latest\n",
    "def create_model(heads,\n",
    "                 embeddings_size=1376,\n",
    "                 learning_rate=0.1,\n",
    "                 end_lr_factor=1.0,\n",
    "                 dropout=0.0,\n",
    "                 decay_steps=1000,\n",
    "                 loss_weights=None,\n",
    "                 hidden_layer_sizes=[512, 256],\n",
    "                 weight_decay=0.0,\n",
    "                 seed=None):\n",
    "  \"\"\"\n",
    "  Creates linear probe or multilayer perceptron using LARS + cosine decay.\n",
    "\n",
    "  \"\"\"\n",
    "  inputs = tf.keras.Input(shape=(embeddings_size,))\n",
    "  hidden = inputs\n",
    "  # If no hidden_layer_sizes are provided, model will be a linear probe.\n",
    "  for size in hidden_layer_sizes:\n",
    "    hidden = tf.keras.layers.Dense(\n",
    "        size,\n",
    "        activation='relu',\n",
    "        kernel_initializer=tf.keras.initializers.HeUniform(seed=seed),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2=weight_decay),\n",
    "        bias_regularizer=tf.keras.regularizers.l2(l2=weight_decay))(\n",
    "            hidden)\n",
    "    hidden = tf.keras.layers.BatchNormalization()(hidden)\n",
    "    hidden = tf.keras.layers.Dropout(dropout, seed=seed)(hidden)\n",
    "  output = tf.keras.layers.Dense(\n",
    "      units=len(heads),\n",
    "      activation='sigmoid',\n",
    "      kernel_initializer=tf.keras.initializers.HeUniform(seed=seed))(\n",
    "          hidden)\n",
    "\n",
    "  outputs = {}\n",
    "  for i, head in enumerate(heads):\n",
    "    outputs[head] = tf.keras.layers.Lambda(\n",
    "        lambda x: x[..., i:i + 1], name=head.lower())(\n",
    "            output)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "  learning_rate_fn = tf.keras.experimental.CosineDecay(\n",
    "      tf.cast(learning_rate, tf.float32),\n",
    "      tf.cast(decay_steps, tf.float32),\n",
    "      alpha=tf.cast(end_lr_factor, tf.float32))\n",
    "      \n",
    "  model.compile(\n",
    "      optimizer=tfm.optimization.lars_optimizer.LARS(\n",
    "          learning_rate=learning_rate_fn),\n",
    "      loss=dict([(head, 'binary_crossentropy') for head in heads]),\n",
    "      loss_weights=loss_weights or dict([(head, 1.) for head in heads]),\n",
    "      weighted_metrics=['AUC'])\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    file_names: Iterable[str],\n",
    "    df_labels: pd.DataFrame,\n",
    "    head_name: str,\n",
    "    train_label: str,\n",
    "    validate_label: str,\n",
    "    model: tf.keras.Model = None,\n",
    "    batch_size: int = 512,\n",
    "    num_epochs: int = 300,\n",
    ") -> tf.keras.Model:\n",
    "  \"\"\"Train a classification model from a set of .tfrecord image embeddings and their labels.\n",
    "\n",
    "  Args:\n",
    "    file_names: The set of .tfrecord image embedding file names.\n",
    "    df_labels: Data frame containing labels and splits. See below for required column names.\n",
    "    head_name: The name of the head/column to train on, from `df_labels`.\n",
    "    train_label: The value of the \"split\" column of `df_labels` that indicates a training sample.\n",
    "    validate_label: The value of the \"split\" column of `df_labels` that indicates a validation sample.\n",
    "    model: The model to train. Defaults to the model from `train_lib.create_model` if none is specified. \n",
    "    batch_size: Batch size for training.\n",
    "    num_epochs: Number of epochs to train.\n",
    "\n",
    "  The `df_labels` DataFrame must contain the follow columns with the specified headings:\n",
    "  - \"{head_name}\" (equal to the `head_name` param): The label/outcome to train on.\n",
    "  - \"image_id\": Corresponds to the image/id feature key within the TFRecord.\n",
    "  - \"split\": Indicates the dataset split. ie. train/test/validation\n",
    "\n",
    "  Example `df_labels` contents:\n",
    "\n",
    "  image_id,split,AIRSPACE_OPACITY\n",
    "  004.png,train,0.0\n",
    "  001.png,train,0.0\n",
    "  000.png,validate,1.0\n",
    "\n",
    "  Returns:\n",
    "    The trained model\n",
    "  \"\"\"\n",
    "\n",
    "  # Create training Dataset\n",
    "  training_df = df_labels[df_labels['split'] == train_label]\n",
    "  training_labels = dict(\n",
    "      zip(training_df['image_id'], training_df[head_name].astype(int))\n",
    "  )\n",
    "  training_data = train_lib.get_dataset(file_names, labels=training_labels)\n",
    "\n",
    "  # Create validation Dataset\n",
    "  validation_data = None\n",
    "  if validate_label:\n",
    "    validate_df = df_labels[df_labels['split'] == validate_label]\n",
    "    validate_labels = dict(zip(validate_df['image_id'], validate_df[head_name].astype(int)))\n",
    "    validation_data = (\n",
    "        train_lib.get_dataset(file_names, labels=validate_labels).batch(1).cache()\n",
    "    )\n",
    "\n",
    "  # Get default model if none was specified\n",
    "  model = model or train_lib.create_model([head_name])\n",
    "  model.fit(\n",
    "      x=training_data.batch(batch_size).prefetch(tf.data.AUTOTUNE).cache(),\n",
    "      validation_data=validation_data,\n",
    "      epochs=num_epochs,\n",
    "  )\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model([DIAGNOSIS])\n",
    "                 \n",
    "model = train_model(\n",
    "    df_labels=df,\n",
    "    file_names=glob.glob(os.path.join(EMBEDDINGS_DIR, '*.tfrecord')),\n",
    "    train_label='train',\n",
    "    validate_label='validate',\n",
    "    head_name=DIAGNOSIS,\n",
    "    batch_size=512,\n",
    "    num_epochs=20,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: serialize model for later use\n",
    "# model.save(\"embeddings_model\", include_optimizer=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cxr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3ac608b8f9188be2227ae82298dfd5de684cbdc4496f362d4b3b9040509447c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
